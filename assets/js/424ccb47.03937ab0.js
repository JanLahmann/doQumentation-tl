"use strict";(globalThis.webpackChunkdoqumentation=globalThis.webpackChunkdoqumentation||[]).push([[9778],{15176(a,n,i){i.r(n),i.d(n,{assets:()=>g,contentTitle:()=>r,default:()=>c,frontMatter:()=>l,metadata:()=>e,toc:()=>o});const e=JSON.parse('{"id":"tutorials/sml-classification","title":"Hybrid quantum-enhanced ensemble classification (daloy ng grid stability workflow)","description":"Bumuo at suriin ang hybrid quantum\u2013classical ensemble para sa klasipikasyon ng katatagan ng grid sa IBM QPU gamit ang Singularity Qiskit Function ng Multiverse Computing.","source":"@site/i18n/tl/docusaurus-plugin-content-docs/current/tutorials/sml-classification.mdx","sourceDirName":"tutorials","slug":"/tutorials/sml-classification","permalink":"/tutorials/sml-classification","draft":false,"unlisted":false,"editUrl":"https://github.com/JanLahmann/doQumentation/tree/main/docs/tutorials/sml-classification.mdx","tags":[],"version":"current","frontMatter":{"title":"Hybrid quantum-enhanced ensemble classification (daloy ng grid stability workflow)","sidebar_label":"Hybrid quantum-enhanced ensemble classification (daloy ng grid stability workflow)","description":"Bumuo at suriin ang hybrid quantum\u2013classical ensemble para sa klasipikasyon ng katatagan ng grid sa IBM QPU gamit ang Singularity Qiskit Function ng Multiverse Computing.","notebook_path":"docs/tutorials/sml-classification.ipynb"},"sidebar":"tutorialsSidebar","previous":{"title":"Lutasin ang Market Split problem gamit ang Iskay Quantum Optimizer ng Kipu Quantum","permalink":"/tutorials/solve-market-split-problem-with-iskay-quantum-optimizer"},"next":{"title":"Simulate ang 2D tilted-field Ising gamit ang QESEM function","permalink":"/tutorials/qedma-2d-ising-with-qesem"}}');var t=i(74848),s=i(28453);const l={title:"Hybrid quantum-enhanced ensemble classification (daloy ng grid stability workflow)",sidebar_label:"Hybrid quantum-enhanced ensemble classification (daloy ng grid stability workflow)",description:"Bumuo at suriin ang hybrid quantum\u2013classical ensemble para sa klasipikasyon ng katatagan ng grid sa IBM QPU gamit ang Singularity Qiskit Function ng Multiverse Computing.",notebook_path:"docs/tutorials/sml-classification.ipynb"},r=void 0,g={},o=[{value:"Background",id:"background",level:2},{value:"Requirements",id:"requirements",level:2},{value:"Setup",id:"setup",level:2},{value:"Download the dataset",id:"download-the-dataset",level:3},{value:"Import required packages",id:"import-required-packages",level:3},{value:"Set constant variables",id:"set-constant-variables",level:3},{value:"Connect to IBM Quantum and load the Singularity function",id:"connect-to-ibm-quantum-and-load-the-singularity-function",level:3},{value:"Define helper functions",id:"define-helper-functions",level:3},{value:"Step 1: Map classical inputs to a quantum problem",id:"step-1-map-classical-inputs-to-a-quantum-problem",level:2},{value:"Data loading and preprocessing",id:"data-loading-and-preprocessing",level:3},{value:"Classical baseline: AdaBoost reference",id:"classical-baseline-adaboost-reference",level:3},{value:"Step 2: Optimize problem for quantum hardware execution",id:"step-2-optimize-problem-for-quantum-hardware-execution",level:2},{value:"Step 3: Execute using Qiskit primitives",id:"step-3-execute-using-qiskit-primitives",level:2},{value:"Baseline",id:"baseline",level:3},{value:"Increase the number of learners",id:"increase-the-number-of-learners",level:3},{value:"Regularization",id:"regularization",level:3},{value:"Step 4: Post-process and return result in desired classical format",id:"step-4-post-process-and-return-result-in-desired-classical-format",level:2},{value:"Evaluate metrics for each configuration",id:"evaluate-metrics-for-each-configuration",level:3},{value:"Visualize quality trends across configurations",id:"visualize-quality-trends-across-configurations",level:3},{value:"Interpretation",id:"interpretation",level:3},{value:"Appendix: Scaling benefits and enhancements",id:"appendix-scaling-benefits-and-enhancements",level:2},{value:"References",id:"references",level:2},{value:"Tutorial survey",id:"tutorial-survey",level:2}];function u(a){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...a.components},{OpenInLabBanner:e}=n;return e||function(a,n){throw new Error("Expected "+(n?"component":"object")+" `"+a+"` to be defined: you likely forgot to import, pass, or provide it.")}("OpenInLabBanner",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e,{notebookPath:"docs/tutorials/sml-classification.ipynb"}),"\n","\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Pagtatantya ng paggamit: 20 minuto sa QPU time para sa bawat gawain sa isang Eagle r3 processor. (PAALALA: Ito ay pagtatantya lamang. Maaaring mag-iba ang inyong runtime.)"})}),"\n",(0,t.jsx)(n.h2,{id:"background",children:"Background"}),"\n",(0,t.jsx)(n.p,{children:'Ang tutorial na ito ay nagpapakita ng hybrid quantum\u2013classical workflow na nagpapahusay sa isang klasikal na ensemble gamit ang quantum optimization step. Ginagamit ang "Singularity Machine Learning \u2013 Classification" ng Multiverse Computing (isang Qiskit Function), magsasanay tayo ng grupo ng konbensyonal na mga learner (halimbawa, decision trees, k-NN, logistic regression) at pagkatapos ay pahusayin ang grupong iyon gamit ang quantum layer upang mapabuti ang diversity at generalization. Ang layunin ay praktikal: sa isang tunay na gawain ng paghula ng katatagan ng grid, ihahambing natin ang malakas na klasikal na baseline sa isang quantum-optimized na alternatibo sa ilalim ng parehong data splits, upang makita ninyo kung saan nakakatulong ang quantum step at ano ang gastos nito.'}),"\n",(0,t.jsx)(n.p,{children:"Bakit ito mahalaga: ang pagpili ng magandang subset mula sa maraming mahinang learner ay isang kombinatoryal na problema na mabilis na lumalaki sa laki ng ensemble. Ang mga klasikal na heuristic tulad ng boosting, bagging, at stacking ay mahusay sa katamtamang sukat ngunit maaaring mahirapan na tuklasin nang epektibo ang malalaking, redundant na mga library ng mga modelo. Ang function ay nagsasama ng mga quantum algorithm - partikular ang QAOA (at opsyonal na VQE sa ibang mga configuration) - upang mas epektibong magsaliksik sa espasyong iyon pagkatapos masanay ang mga klasikal na learner, na nagpapataas ng pagkakataon na makahanap ng compact, diverse na subset na mas mahusay sa generalization."}),"\n",(0,t.jsx)(n.p,{children:"Mahalagang tandaan, ang sukat ng data ay hindi limitado ng mga qubit. Ang mabigat na gawain sa data \u2014 preprocessing, pagsasanay ng learner pool, at evaluation \u2014 ay nananatiling klasikal at kayang humawak ng milyun-milyong halimbawa. Ang mga qubit ay tumutukoy lamang ng laki ng ensemble na ginagamit sa quantum selection step. Ang paghihiwalayan na ito ang nagpapahintulot ng approach sa kasalukuyang hardware: pinapanatili ninyo ang pamilyar na scikit-learn workflow para sa data at model training habang tinatawag ang quantum step sa pamamagitan ng malinis na action interface sa Qiskit Functions."}),"\n",(0,t.jsx)(n.p,{children:"Sa praktis, bagaman maaaring magbigay ng iba't ibang uri ng learner sa ensemble (hal., decision trees, logistic regression, o k-NN), ang Decision Trees ay karaniwang pinakamahusay. Ang optimizer ay patuloy na pumipili ng mas malakas na miyembro ng ensemble\u2014kapag ibinigay ang heterogeneous na mga learner, ang mas mahinang mga modelo tulad ng linear regressors ay karaniwang tinatanggal pabor sa mas expressive na mga ito tulad ng Decision Trees."}),"\n",(0,t.jsxs)(n.p,{children:["Ang inyong gagawin dito: maghanda at balansehin ang grid-stability dataset; magtatag ng klasikal na AdaBoost baseline; magpatakbo ng ilang quantum configuration na nag-iiba ng ensemble width at regularization; magsagawa sa IBM\xae simulator o QPU sa pamamagitan ng Qiskit Serverless; at ihambing ang accuracy, precision, recall, at F1 sa lahat ng runs. Sa daan, gagamitin ninyo ang action pattern ng function (",(0,t.jsx)(n.code,{children:"create"}),", ",(0,t.jsx)(n.code,{children:"fit"}),", ",(0,t.jsx)(n.code,{children:"predict"}),", ",(0,t.jsx)(n.code,{children:"fit_predict"}),", ",(0,t.jsx)(n.code,{children:"create_fit_predict"}),") at mga pangunahing control:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Mga uri ng regularization: ",(0,t.jsx)(n.code,{children:"onsite"})," (\u03bb) para sa direktang sparsity at ",(0,t.jsx)(n.code,{children:"alpha"})," para sa ratio-based trade-off sa pagitan ng interaction at onsite terms"]}),"\n",(0,t.jsxs)(n.li,{children:["Auto-regularization: itakda ang ",(0,t.jsx)(n.code,{children:'regularization="auto"'})," na may target selection ratio upang awtomatikong umangkop ang sparsity"]}),"\n",(0,t.jsx)(n.li,{children:"Mga opsyon ng optimizer: simulator kontra QPU, mga pag-uulit, klasikal na optimizer at mga opsyon nito, lalim ng transpilation, at mga setting ng runtime sampler/estimator"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Ang mga benchmark sa dokumentasyon ay nagpapakita na ang accuracy ay bumubuti habang tumataas ang bilang ng mga learner (qubit) sa mahihirap na problema, at ang quantum classifier ay tumutugma o lumalampas sa maihahambing na klasikal na ensemble. Sa tutorial na ito, uulitin ninyo ang workflow mula simula hanggang dulo at susuriin kung kailan ang pagtaas ng ensemble width o paglipat sa adaptive regularization ay nagbubunga ng mas magandang F1 sa makatwirang paggamit ng resources. Ang resulta ay isang makatotohanang pananaw kung paano ang quantum optimization step ay maaaring kumplemento, sa halip na palitan, ang klasikal na ensemble learning sa tunay na mga aplikasyon."}),"\n",(0,t.jsx)(n.h2,{id:"requirements",children:"Requirements"}),"\n",(0,t.jsx)(n.p,{children:"Bago magsimula sa tutorial na ito, tiyaking naka-install sa inyong Python environment ang sumusunod na mga package:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"qiskit[visualization]~=2.1.0"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"qiskit-serverless~=0.24.0"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"qiskit-ibm-runtime v0.40.1"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"qiskit-ibm-catalog~=0.8.0"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"scikit-learn==1.5.2"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"pandas>=2.0.0,<3.0.0"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"imbalanced-learn~=0.12.3"})}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"setup",children:"Setup"}),"\n",(0,t.jsx)(n.p,{children:"Sa seksyong ito, magsisimula tayo ng Qiskit Serverless client at ikakarga ang Singularity Machine Learning \u2013 Classification function na ibinigay ng Multiverse Computing.\nSa Qiskit Serverless, maaari ninyong patakbuhin ang hybrid quantum\u2013classical workflow sa IBM managed cloud infrastructure nang hindi nag-aalala sa resource management.\nKakailanganin ninyo ng IBM Quantum Platform API key at inyong cloud resource name (CRN) upang mag-authenticate at ma-access ang Qiskit Functions."}),"\n",(0,t.jsx)(n.h3,{id:"download-the-dataset",children:"Download the dataset"}),"\n",(0,t.jsxs)(n.p,{children:["Upang patakbuhin ang tutorial na ito, gagamitin natin ang pre-processed na ",(0,t.jsx)(n.strong,{children:"grid stability classification dataset"})," na naglalaman ng mga naka-label na sensor reading ng power system.\nAng sumusunod na cell ay awtomatikong lumilikha ng kinakailangang folder structure at dini-download ang parehong training at test file nang direkta sa inyong environment gamit ang ",(0,t.jsx)(n.code,{children:"wget"}),".\nKung mayroon na kayong mga file na ito locally, ang hakbang na ito ay ligtas na mag-overwrite sa kanila upang matiyak ang version consistency."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Added by doQumentation \u2014 installs packages not in the Binder environment\n%pip install -q imbalanced-learn scikit-learn\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'## Download dataset for Grid Stability Classification\n\n# Create data directory if it doesn\'t exist\n!mkdir -p data_tutorial/grid_stability\n\n# Download the training and test sets from the official Qiskit documentation repo\n!wget -q --show-progress -O data_tutorial/grid_stability/train.csv \\\n  https://raw.githubusercontent.com/Qiskit/documentation/main/datasets/tutorials/grid_stability/train.csv\n\n!wget -q --show-progress -O data_tutorial/grid_stability/test.csv \\\n  https://raw.githubusercontent.com/Qiskit/documentation/main/datasets/tutorials/grid_stability/test.csv\n\n# Check the files have been downloaded\n!echo "Dataset files downloaded:"\n!ls -lh data_tutorial/grid_stability/*.csv\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"data_tutorial/grid_ 100%[===================>] 612.94K  --.-KB/s    in 0.01s\ndata_tutorial/grid_ 100%[===================>] 108.19K  --.-KB/s    in 0.006s\nDataset files downloaded:\n-rw-r--r-- 1 coder coder 109K Nov  8 18:50 data_tutorial/grid_stability/test.csv\n-rw-r--r-- 1 coder coder 613K Nov  8 18:50 data_tutorial/grid_stability/train.csv\n"})}),"\n",(0,t.jsx)(n.h3,{id:"import-required-packages",children:"Import required packages"}),"\n",(0,t.jsxs)(n.p,{children:["Sa seksyong ito, iai-import natin ang lahat ng Python package at Qiskit module na gagamitin sa buong tutorial.\nKasama dito ang mga pangunahing siyentipikong library para sa data handling at model evaluation - tulad ng ",(0,t.jsx)(n.code,{children:"NumPy"}),", ",(0,t.jsx)(n.code,{children:"pandas"}),", at ",(0,t.jsx)(n.code,{children:"scikit-learn"})," - kasama ang mga visualization tool at Qiskit component para sa pagpapatakbo ng quantum-enhanced model.\nIai-import din natin ang ",(0,t.jsx)(n.code,{children:"QiskitRuntimeService"})," at ",(0,t.jsx)(n.code,{children:"QiskitFunctionsCatalog"})," upang kumonekta sa IBM Quantum\xae services at ma-access ang Singularity Machine Learning function."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from typing import Tuple\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom imblearn.over_sampling import RandomOverSampler\nfrom qiskit_ibm_catalog import QiskitFunctionsCatalog\nfrom qiskit_ibm_runtime import QiskitRuntimeService\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import (\n    accuracy_score,\n    f1_score,\n    precision_score,\n    recall_score,\n)\nfrom sklearn.model_selection import train_test_split\n\nwarnings.filterwarnings("ignore")\n'})}),"\n",(0,t.jsx)(n.h3,{id:"set-constant-variables",children:"Set constant variables"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'IBM_TOKEN = ""\nIBM_INSTANCE_TEST = ""\nIBM_INSTANCE_QUANTUM = ""\nFUNCTION_NAME = "multiverse/singularity"\nRANDOM_STATE: int = 123\nTRAIN_PATH = "data_tutorial/grid_stability/train.csv"\nTEST_PATH = "data_tutorial/grid_stability/test.csv"\n'})}),"\n",(0,t.jsx)(n.h3,{id:"connect-to-ibm-quantum-and-load-the-singularity-function",children:"Connect to IBM Quantum and load the Singularity function"}),"\n",(0,t.jsxs)(n.p,{children:["Susunod, mag-authenticate tayo sa IBM Quantum services at ika-karga ang Singularity Machine Learning \u2013 Classification function mula sa Qiskit Functions Catalog.\nAng ",(0,t.jsx)(n.code,{children:"QiskitRuntimeService"})," ay nagtatatag ng secure na koneksyon sa IBM Quantum Platform gamit ang inyong API token at instance CRN, na nagbibigay ng access sa quantum backend.\nAng ",(0,t.jsx)(n.code,{children:"QiskitFunctionsCatalog"})," ay ginagamit pagkatapos upang kunin ang Singularity function sa pamamagitan ng pangalan (",(0,t.jsx)(n.code,{children:'"multiverse/singularity"'}),"), na nagbibigay-daan sa atin na tawagin ito mamaya para sa hybrid quantum\u2013classical computation.\nKung matagumpay ang setup, makikita ninyo ang mensahe ng kumpirmasyon na nagsasabing ang function ay na-load nang tama."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'service = QiskitRuntimeService(\n    token=IBM_TOKEN,\n    channel="ibm_quantum_platform",\n    instance=IBM_INSTANCE_QUANTUM,\n)\n\nbackend = service.least_busy()\ncatalog = QiskitFunctionsCatalog(\n    token=IBM_TOKEN,\n    instance=IBM_INSTANCE_TEST,\n    channel="ibm_quantum_platform",\n)\nsingularity = catalog.load(FUNCTION_NAME)\nprint(\n    "Successfully connected to IBM Qiskit Serverless and loaded the Singularity function."\n)\nprint("Catalog:", catalog)\nprint("Singularity function:", singularity)\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"Successfully connected to IBM Qiskit Serverless and loaded the Singularity function.\nCatalog: <QiskitFunctionsCatalog>\nSingularity function: QiskitFunction(multiverse/singularity)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"define-helper-functions",children:"Define helper functions"}),"\n",(0,t.jsx)(n.p,{children:"Bago patakbuhin ang mga pangunahing eksperimento, magtutukoy tayo ng ilang maliliit na utility function na nagpapasimple ng data loading at model evaluation."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Ang ",(0,t.jsx)(n.code,{children:"load_data()"})," ay nagbabasa ng mga input CSV file sa NumPy array, na naghihiwalay ng mga feature at label para sa compatibility sa ",(0,t.jsx)(n.code,{children:"scikit-learn"})," at quantum workflow."]}),"\n",(0,t.jsxs)(n.li,{children:["Ang ",(0,t.jsx)(n.code,{children:"evaluate_predictions()"})," ay kinukumputa ang mga pangunahing performance metric - accuracy, precision, recall, at F1-score - at opsyonal na nag-uulat ng runtime kung ibinigay ang timing information."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Ang mga helper function na ito ay nagpapasimple ng paulit-ulit na operasyon mamaya sa notebook at nagsisiguro ng pare-parehong metric reporting sa parehong klasikal at quantum classifier."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'def load_data(data_path: str) -> Tuple[np.ndarray, np.ndarray]:\n    """Load data from the given path to X and y arrays."""\n    df: pd.DataFrame = pd.read_csv(data_path)\n    return df.iloc[:, :-1].values, df.iloc[:, -1].values\n\ndef evaluate_predictions(predictions, y_true):\n    """Compute and print accuracy, precision, recall, and F1 score."""\n    accuracy = accuracy_score(y_true, predictions)\n    precision = precision_score(y_true, predictions)\n    recall = recall_score(y_true, predictions)\n    f1 = f1_score(y_true, predictions)\n    print("Accuracy:", accuracy)\n    print("Precision:", precision)\n    print("Recall:", recall)\n    print("F1:", f1)\n    return accuracy, precision, recall, f1\n'})}),"\n",(0,t.jsx)(n.h2,{id:"step-1-map-classical-inputs-to-a-quantum-problem",children:"Step 1: Map classical inputs to a quantum problem"}),"\n",(0,t.jsx)(n.p,{children:"Magsisimula tayo sa pamamagitan ng paghahanda ng dataset para sa hybrid quantum\u2013classical experimentation. Ang layunin ng hakbang na ito ay i-convert ang raw grid-stability data sa balanced training, validation, at test split na maaaring gamitin nang pare-pareho ng parehong klasikal at quantum workflow. Ang pagpapanatili ng magkaparehong split ay nagsisiguro na ang mga paghahambing ng performance sa susunod ay patas at maiuulit."}),"\n",(0,t.jsx)(n.h3,{id:"data-loading-and-preprocessing",children:"Data loading and preprocessing"}),"\n",(0,t.jsx)(n.p,{children:"Una, ika-karga natin ang training at test CSV file, lumikha ng validation split, at balansehin ang dataset gamit ang random over-sampling. Ang pagbabalanse ay pumipigil sa bias tungo sa majority class at nagbibigay ng mas matatag na learning signal para sa parehong klasikal at quantum ensemble model."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Load and upload the data\nX_train, y_train = load_data(TRAIN_PATH)\nX_test, y_test = load_data(TEST_PATH)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train, y_train, test_size=0.2, random_state=RANDOM_STATE\n)\n\n# Balance the dataset through over-sampling of the positive class\nros = RandomOverSampler(random_state=RANDOM_STATE)\nX_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)\n\nprint("Shapes:")\nprint("  X_train_bal:", X_train_bal.shape)\nprint("  y_train_bal:", y_train_bal.shape)\nprint("  X_val:", X_val.shape)\nprint("  y_val:", y_val.shape)\nprint("  X_test:", X_test.shape)\nprint("  y_test:", y_test.shape)\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"Shapes:\n  X_train_bal: (5104, 12)\n  y_train_bal: (5104,)\n  X_val: (850, 12)\n  y_val: (850,)\n  X_test: (750, 12)\n  y_test: (750,)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"classical-baseline-adaboost-reference",children:"Classical baseline: AdaBoost reference"}),"\n",(0,t.jsx)(n.p,{children:"Bago magpatakbo ng anumang quantum optimization, magsasanay tayo ng malakas na klasikal na baseline - isang karaniwang AdaBoost classifier - sa parehong balanced data. Nagbibigay ito ng maiuulit na reference point para sa paghahambing sa susunod, na tumutulong na sukatin kung ang quantum optimization ay nagpapabuti ng generalization o kahusayan lampas sa mahusay na na-tune na klasikal na ensemble."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# ----- Classical baseline: AdaBoost -----\nbaseline = AdaBoostClassifier(n_estimators=60, random_state=RANDOM_STATE)\nbaseline.fit(X_train_bal, y_train_bal)\nbaseline_pred = baseline.predict(X_test)\nprint("Classical AdaBoost baseline:")\n_ = evaluate_predictions(baseline_pred, y_test)\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"Classical AdaBoost baseline:\nAccuracy: 0.7893333333333333\nPrecision: 1.0\nRecall: 0.7893333333333333\nF1: 0.8822652757078987\n"})}),"\n",(0,t.jsx)(n.h2,{id:"step-2-optimize-problem-for-quantum-hardware-execution",children:"Step 2: Optimize problem for quantum hardware execution"}),"\n",(0,t.jsxs)(n.p,{children:["Ang gawain ng ensemble selection ay ginagawang kombinatoryal na optimization problem kung saan ang bawat mahinang learner ay isang binary decision variable, at ang layunin ay nagbabalanse ng accuracy sa sparsity sa pamamagitan ng regularization term. Ang ",(0,t.jsx)(n.code,{children:"QuantumEnhancedEnsembleClassifier"})," ay nalulutas ito gamit ang QAOA sa IBM hardware, habang pinapayagan pa rin ang simulator-based exploration. Ang ",(0,t.jsx)(n.code,{children:"optimizer_options"})," ay kumokontrol sa hybrid loop: ang ",(0,t.jsx)(n.code,{children:"simulator=False"})," ay nagdidirekta ng mga circuit sa napiling QPU, ang ",(0,t.jsx)(n.code,{children:"num_solutions"})," ay nagpapataas ng search breadth, at ang ",(0,t.jsx)(n.code,{children:"classical_optimizer_options"})," (para sa panloob na klasikal na optimizer) ay namamahala sa convergence; ang mga value na malapit sa 60 iteration ay magandang balanse para sa kalidad at runtime. Ang mga runtime option - tulad ng katamtamang circuit depth (",(0,t.jsx)(n.code,{children:"reps"}),') at karaniwang transpilation effort - ay tumutulong na masiguro ang matatag na performance sa iba\'t ibang device. Ang configuration sa ibaba ay ang "best-results" profile na gagamitin natin para sa hardware run; maaari din kayong lumikha ng purong simulated variant sa pamamagitan ng pagpalit sa ',(0,t.jsx)(n.code,{children:"simulator=True"})," upang mag-dry-run ng workflow nang hindi gumagamit ng QPU time."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# QAOA / runtime configuration for best results on hardware\noptimizer_options = {\n    "simulator": False,  # set True to test locally without QPU\n    "num_solutions": 100_000,  # broaden search over candidate ensembles\n    "reps": 3,  # QAOA depth (circuit layers)\n    "optimization_level": 3,  # transpilation effort\n    "num_transpiler_runs": 30,  # explore multiple layouts\n    "classical_optimizer": "COBYLA",  # robust default for this landscape\n    "classical_optimizer_options": {\n        "maxiter": 60  # practical convergence budget\n    },\n    # You can pass backend-specific options; leaving None uses least-busy routing\n    "estimator_options": None,\n    "sampler_options": None,\n}\n\nprint("Configured hardware optimization profile:")\nfor key, value in optimizer_options.items():\n    print(f"  {key}: {value}")\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"Configured hardware optimization profile:\n  simulator: False\n  num_solutions: 100000\n  reps: 3\n  optimization_level: 3\n  num_transpiler_runs: 30\n  classical_optimizer: COBYLA\n  classical_optimizer_options: {'maxiter': 60}\n  estimator_options: None\n  sampler_options: None\n"})}),"\n",(0,t.jsx)(n.h2,{id:"step-3-execute-using-qiskit-primitives",children:"Step 3: Execute using Qiskit primitives"}),"\n",(0,t.jsxs)(n.p,{children:["Ngayon ay isasagawa natin ang buong workflow gamit ang ",(0,t.jsx)(n.code,{children:"create_fit_predict"})," action ng Singularity function upang magsanay, mag-optimize, at suriin ang ",(0,t.jsx)(n.code,{children:"QuantumEnhancedEnsembleClassifier"})," mula simula hanggang dulo sa IBM infrastructure. Ang function ay bumubuo ng ensemble, naglalapat ng quantum optimization sa pamamagitan ng Qiskit primitive, at nagbabalik ng parehong mga prediction at job metadata (kasama ang runtime at resource usage). Ang klasikal na data split mula sa Step 1 ay muling ginagamit para sa reproducibility, na may validation data na ipinasa sa pamamagitan ng ",(0,t.jsx)(n.code,{children:"fit_params"})," upang ang optimization ay makapag-tune ng mga hyperparameter sa loob habang pinapanatiling hindi nagagalaw ang held-out test set."]}),"\n",(0,t.jsxs)(n.p,{children:["Sa hakbang na ito, tutuklasin natin ang ilang configuration ng quantum ensemble upang maunawaan kung paano ang mga pangunahing parameter - partikular na ",(0,t.jsx)(n.code,{children:"num_learners"})," at ",(0,t.jsx)(n.code,{children:"regularization"})," - ay nakakaapekto sa parehong kalidad ng resulta at paggamit ng QPU."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Ang ",(0,t.jsx)(n.code,{children:"num_learners"})," ay tumutukoy ng ensemble width (at implicitly, ang bilang ng mga qubit), na nakakaimpluwensya sa kapasidad ng modelo at computational cost."]}),"\n",(0,t.jsxs)(n.li,{children:["Ang ",(0,t.jsx)(n.code,{children:"regularization"})," ay kumokontrol ng sparsity at overfitting, na humuhubog kung gaano karaming learner ang nananatiling aktibo pagkatapos ng optimization."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Sa pamamagitan ng pag-iba-iba ng mga parameter na ito, makikita natin kung paano nakikipag-ugnayan ang ensemble width at regularization: ang pagtaas ng width ay karaniwang nagpapabuti ng F1 ngunit mas mahal sa QPU time, habang ang mas malakas o adaptive regularization ay maaaring magpabuti ng generalization sa halos parehong hardware footprint. Ang susunod na mga subsection ay dumadaan sa tatlong representative configuration upang ipakita ang mga epektong ito."}),"\n",(0,t.jsx)(n.h3,{id:"baseline",children:"Baseline"}),"\n",(0,t.jsxs)(n.p,{children:["Ang configuration na ito ay gumagamit ng ",(0,t.jsx)(n.code,{children:"num_learners = 10"})," at ",(0,t.jsx)(n.code,{children:"regularization = 7"}),"."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Ang ",(0,t.jsx)(n.code,{children:"num_learners"})," ay kumokontrol ng ensemble width \u2014 epektibo ang bilang ng mga mahinang learner na pinagsama at, sa quantum hardware, ang ",(0,t.jsx)(n.strong,{children:"bilang ng mga qubit na kailangan"}),". Ang mas malaking value ay nagpapalawig ng combinatorial search space at maaaring magpabuti ng accuracy at recall, ngunit nagpapataas din ng circuit width, compilation time, at pangkalahatang paggamit ng QPU."]}),"\n",(0,t.jsxs)(n.li,{children:["Ang ",(0,t.jsx)(n.code,{children:"regularization"}),' ay nagtatakda ng penalty strength para sa pagsasama ng karagdagang mga learner. Sa default na "onsite" regularization, ang mas mataas na value ay nagpapatibay ng mas malakas na sparsity (mas kaunting learner na pinapanatili), habang ang mas mababang value ay nagpapahintulot ng mas kumplikadong ensemble.']}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Ang setup na ito ay nagbibigay ng low-cost baseline, na nagpapakita kung paano kumikilos ang isang maliit na ensemble bago palawakin ang width o mag-tune ng sparsity."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Problem scale and regularization\nNUM_LEARNERS = 10\nREGULARIZATION = 7\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# ----- Quantum-enhanced ensemble on IBM hardware -----\nprint("\\n-- Submitting quantum-enhanced ensemble job --")\njob_1 = singularity.run(\n    action="create_fit_predict",\n    name="grid_stability_qeec",\n    quantum_classifier="QuantumEnhancedEnsembleClassifier",\n    num_learners=NUM_LEARNERS,\n    regularization=REGULARIZATION,\n    optimizer_options=optimizer_options,  # from Step 2\n    backend_name=backend,  # least-busy compatible backend\n    instance=IBM_INSTANCE_QUANTUM,\n    random_state=RANDOM_STATE,\n    X_train=X_train_bal,\n    y_train=y_train_bal,\n    X_test=X_test,\n    fit_params={"validation_data": (X_val, y_val)},\n    options={"save": False},\n)\nresult_1 = job_1.result()\nprint("Action status:", result_1.get("status"))\nprint("Action message:", result_1.get("message"))\nprint("Metadata:", result_1.get("metadata"))\nqeec_pred_job_1 = np.array(result_1["data"]["predictions"])\n_ = evaluate_predictions(qeec_pred_job_1, y_test)\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"-- Submitting quantum-enhanced ensemble job --\nAction status: ok\nAction message: Classifier created, fitted, and predicted.\nMetadata: {'resource_usage': {'RUNNING: MAPPING': {'CPU_TIME': 267.05158376693726}, 'RUNNING: WAITING_QPU': {'CPU_TIME': 3336.8785166740417}, 'RUNNING: POST_PROCESSING': {'CPU_TIME': 152.4274561405182}, 'RUNNING: EXECUTING_QPU': {'QPU_TIME': 1550.1889700889587}}}\nAccuracy: 0.868\nPrecision: 1.0\nRecall: 0.868\nF1: 0.9293361884368309\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'status_1 = job_1.status()\nprint("\\nQuantum job status:", status_1)\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"Quantum job status: DONE\n"})}),"\n",(0,t.jsx)(n.h3,{id:"increase-the-number-of-learners",children:"Increase the number of learners"}),"\n",(0,t.jsxs)(n.p,{children:["Dito ay dinadagdagan natin ang ",(0,t.jsx)(n.code,{children:"num_learners"})," mula 10 \u2192 30 habang pinapanatili ang ",(0,t.jsx)(n.code,{children:"regularization = 7"}),"."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Ang mas maraming learner ay nagpapalawig ng hypothesis space, na nagpapahintulot sa modelo na makuha ang mas banayad na pattern, na maaaring bahagyang magtaas ng F1."}),"\n",(0,t.jsx)(n.li,{children:"Sa karamihan ng mga kaso, ang pagkakaiba ng runtime sa pagitan ng 10 at 30 learner ay hindi gaanong malaki, na nagsasaad na ang karagdagang circuit width ay hindi lubhang nagpapataas ng execution cost."}),"\n",(0,t.jsxs)(n.li,{children:["Ang pagpapabuti ng kalidad ay sumusunod pa rin sa ",(0,t.jsx)(n.em,{children:"diminishing-returns curve"}),": ang mga unang pakinabang ay lumalabas habang lumalaki ang ensemble, ngunit nag-plateau ang mga ito habang ang karagdagang mga learner ay nag-aambag ng mas kaunting bagong impormasyon."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Ang eksperimentong ito ay nag-highlight ng quality\u2013efficiency trade-off \u2014 ang pagtaas ng ensemble width ay maaaring mag-alok ng maliliit na accuracy gain nang walang malaking runtime penalty, depende sa backend at transpilation condition."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Problem scale and regularization\nNUM_LEARNERS = 30\nREGULARIZATION = 7\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# ----- Quantum-enhanced ensemble on IBM hardware -----\nprint("\\n-- Submitting quantum-enhanced ensemble job --")\njob_2 = singularity.run(\n    action="create_fit_predict",\n    name="grid_stability_qeec",\n    quantum_classifier="QuantumEnhancedEnsembleClassifier",\n    num_learners=NUM_LEARNERS,\n    regularization=REGULARIZATION,\n    optimizer_options=optimizer_options,  # from Step 2\n    backend_name=backend,  # least-busy compatible backend\n    instance=IBM_INSTANCE_QUANTUM,\n    random_state=RANDOM_STATE,\n    X_train=X_train_bal,\n    y_train=y_train_bal,\n    X_test=X_test,\n    fit_params={"validation_data": (X_val, y_val)},\n    options={"save": False},\n)\nresult_2 = job_2.result()\nprint("Action status:", result_2.get("status"))\nprint("Action message:", result_2.get("message"))\nprint("QPU Time:", result_2.get("metadata"))\nqeec_pred_job_2 = np.array(result_2["data"]["predictions"])\n_ = evaluate_predictions(qeec_pred_job_2, y_test)\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"-- Submitting quantum-enhanced ensemble job --\nAction status: ok\nAction message: Classifier created, fitted, and predicted.\nQPU Time: {'resource_usage': {'RUNNING: MAPPING': {'CPU_TIME': 680.2116754055023}, 'RUNNING: WAITING_QPU': {'CPU_TIME': 80.80395102500916}, 'RUNNING: POST_PROCESSING': {'CPU_TIME': 154.4466371536255}, 'RUNNING: EXECUTING_QPU': {'QPU_TIME': 1095.822762966156}}}\nAccuracy: 0.8946666666666667\nPrecision: 1.0\nRecall: 0.8946666666666667\nF1: 0.944405348346235\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'status_2 = job_2.status()\nprint("\\nQuantum job status:", status_2)\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"Quantum job status: DONE\n"})}),"\n",(0,t.jsx)(n.h3,{id:"regularization",children:"Regularization"}),"\n",(0,t.jsxs)(n.p,{children:["Sa configuration na ito, dinadagdagan natin sa ",(0,t.jsx)(n.code,{children:"num_learners = 60"})," at nagpapakilala ng adaptive regularization upang mas intuitive na pamahalaan ang sparsity."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Sa ",(0,t.jsx)(n.code,{children:'regularization = "auto"'}),", ang optimizer ay awtomatikong nakakakita ng angkop na regularization strength na pumipili ng humigit-kumulang ",(0,t.jsx)(n.code,{children:"regularization_ratio * num_learners"})," na mahinang learner para sa huling ensemble, sa halip na manually na pag-fix ng penalty. Nagbibigay ito ng mas maginhawang interface para sa pamamahala ng balanse sa pagitan ng sparsity at laki ng ensemble."]}),"\n",(0,t.jsxs)(n.li,{children:["Ang ",(0,t.jsx)(n.code,{children:'regularization_type = "alpha"'})," ay tumutukoy kung paano inilalapat ang penalty. Hindi katulad ng ",(0,t.jsx)(n.code,{children:"onsite"}),", na walang hangganan ",(0,t.jsx)(n.code,{children:"[0, \u221e]"}),", ang ",(0,t.jsx)(n.code,{children:"alpha"})," ay may hangganan sa pagitan ng ",(0,t.jsx)(n.code,{children:"[0, 1]"}),", na ginagawang mas madaling i-tune at maintindihan. Ang parameter ay kumokontrol ng trade-off sa pagitan ng indibidwal at pairwise penalty, na nag-aalok ng mas maayos na configuration range."]}),"\n",(0,t.jsxs)(n.li,{children:["Ang ",(0,t.jsx)(n.code,{children:"regularization_desired_ratio \u2248 0.82"})," ay tumutukoy ng target proportion ng mga learner na panatilihing aktibo pagkatapos ng regularization \u2014 dito, humigit-kumulang 82% ng mga learner ay napapanatili, na awtomatikong tinatanggal ang pinakamahina na 18%."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Bagaman ang adaptive regularization ay nagpapasimple ng configuration at tumutulong na mapanatili ang balanseng ensemble, hindi ito kinakailangang gumagarantiya ng mas maganda o mas matatag na performance. Ang aktwal na kalidad ay nakadepende sa pagpili ng angkop na regularization parameter, at ang fine-tuning nito sa pamamagitan ng cross-validation ay maaaring magastos sa computational. Ang pangunahing bentahe ay nakasalalay sa pinabuting usability at interpretability sa halip na direktang accuracy gain."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Problem scale and regularization\nNUM_LEARNERS = 60\nREGULARIZATION = "auto"\nREGULARIZATION_TYPE = "alpha"\nREGULARIZATION_RATIO = 0.82\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# ----- Quantum-enhanced ensemble on IBM hardware -----\nprint("\\n-- Submitting quantum-enhanced ensemble job --")\njob_3 = singularity.run(\n    action="create_fit_predict",\n    name="grid_stability_qeec",\n    quantum_classifier="QuantumEnhancedEnsembleClassifier",\n    num_learners=NUM_LEARNERS,\n    regularization=REGULARIZATION,\n    regularization_type=REGULARIZATION_TYPE,\n    regularization_desired_ratio=REGULARIZATION_RATIO,\n    optimizer_options=optimizer_options,  # from Step 2\n    backend_name=backend,  # least-busy compatible backend\n    instance=IBM_INSTANCE_QUANTUM,\n    random_state=RANDOM_STATE,\n    X_train=X_train_bal,\n    y_train=y_train_bal,\n    X_test=X_test,\n    fit_params={"validation_data": (X_val, y_val)},\n    options={"save": False},\n)\nresult_3 = job_3.result()\nprint("Action status:", result_3.get("status"))\nprint("Action message:", result_3.get("message"))\nprint("Metadata:", result_3.get("metadata"))\nqeec_pred_job_3 = np.array(result_3["data"]["predictions"])\n_ = evaluate_predictions(qeec_pred_job_3, y_test)\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"-- Submitting quantum-enhanced ensemble job --\nAction status: ok\nAction message: Classifier created, fitted, and predicted.\nMetadata: {'resource_usage': {'RUNNING: MAPPING': {'CPU_TIME': 1387.7451872825623}, 'RUNNING: WAITING_QPU': {'CPU_TIME': 95.41597843170166}, 'RUNNING: POST_PROCESSING': {'CPU_TIME': 171.78878355026245}, 'RUNNING: EXECUTING_QPU': {'QPU_TIME': 1146.5584812164307}}}\nAccuracy: 0.908\nPrecision: 1.0\nRecall: 0.908\nF1: 0.9517819706498952\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'status_3 = job_3.status()\nprint("\\nQuantum job status:", status_3)\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"Quantum job status: DONE\n"})}),"\n",(0,t.jsx)(n.h2,{id:"step-4-post-process-and-return-result-in-desired-classical-format",children:"Step 4: Post-process and return result in desired classical format"}),"\n",(0,t.jsxs)(n.p,{children:["Ngayon ay i-post-process natin ang mga output mula sa parehong klasikal at quantum run, na kino-convert ang mga ito sa pare-parehong format para sa downstream evaluation. Ang hakbang na ito ay naghahambing ng predictive quality gamit ang karaniwang mga metric - accuracy, precision, recall, at F1 - at sinusuri kung paano ang ensemble width (",(0,t.jsx)(n.code,{children:"num_learners"}),") at sparsity control (",(0,t.jsx)(n.code,{children:"regularization"}),") ay nakakaimpluwensya sa parehong performance at computational behavior."]}),"\n",(0,t.jsxs)(n.p,{children:["Ang klasikal na AdaBoost baseline ay nagbibigay ng compact at matatag na reference para sa small-scale learning. Mahusay ito sa limitadong ensemble at negligible compute overhead, na sumasalamin sa lakas ng tradisyonal na boosting kapag ang hypothesis space ay tractable pa rin. Ang mga quantum configuration (",(0,t.jsx)(n.code,{children:"qeec_pred_job_1"}),", ",(0,t.jsx)(n.code,{children:"qeec_pred_job_2"}),", at ",(0,t.jsx)(n.code,{children:"qeec_pred_job_3"}),") ay pinalawig ang baseline na ito sa pamamagitan ng pag-embed ng ensemble-selection process sa loob ng variational quantum optimization loop. Binibigyang-daan nito ang system na tuklasin ang eksponensiyal na malalaking subset ng mga learner nang sabay-sabay sa superposition, na tumutugon sa kombinatoryal na katangian ng ensemble selection nang mas epektibo habang tumataas ang sukat."]}),"\n",(0,t.jsxs)(n.p,{children:["Ang mga resulta ay nagpapakita na ang pagtaas ng ",(0,t.jsx)(n.code,{children:"num_learners"})," mula 10 hanggang 30 ay nagpapabuti ng recall at F1, na nagkukumpirma na ang mas malawak na ensemble ay kumukuha ng mas mayamang interaction sa mga mahinang learner. Ang pakinabang ay sublinear sa kasalukuyang hardware - ang bawat karagdagang learner ay nagbubunga ng mas maliit na accuracy increment - ngunit ang pinagbabatayan ng scaling behavior ay nananatiling pabor dahil ang quantum optimizer ay maaaring magsaliksik ng mas malawak na configuration space nang walang eksponensiyal na pagsabog na tipikal sa klasikal na subset selection. Ang regularization ay nagpapakilala ng karagdagang nuance: ang fixed na \u03bb=7 ay nagpapatibay ng pare-parehong sparsity at nag-stabilize ng convergence, samantalang ang adaptive na \u03b1-regularization ay awtomatikong nag-tune ng sparsity batay sa correlation sa pagitan ng mga learner. Ang dynamic pruning na ito ay madalas na nakakamit ng bahagyang mas mataas na F1 para sa parehong qubit width, na binabalanse ang model complexity at generalization."]}),"\n",(0,t.jsxs)(n.p,{children:['Kapag direktang inihambing sa AdaBoost baseline, ang pinakamaliit na quantum configuration (L=10) ay muling gumagawa ng katulad na accuracy, na nagpapatunay sa katumpakan ng hybrid pipeline. Sa mas malalaking width, ang mga quantum variant - lalo na sa auto-regularization - ay nagsisimulang lampasan ang klasikal na baseline nang bahagya, na nagpapakita ng pinabuting recall at F1 nang walang linear growth sa computational cost. Ang mga pagpapabuting ito ay hindi nagsasaad ng agarang "quantum advantage" kundi ',(0,t.jsx)(n.strong,{children:"scaling efficiency"}),": ang quantum optimizer ay nagpapanatili ng tractable performance habang lumalawak ang ensemble, kung saan ang klasikal na approach ay haharapin ang eksponensiyal na paglaki sa subset-selection complexity."]}),"\n",(0,t.jsx)(n.p,{children:"Sa praktis:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Gamitin ang ",(0,t.jsx)(n.strong,{children:"klasikal na baseline"})," para sa mabilis na validation at benchmarking sa maliliit na dataset."]}),"\n",(0,t.jsxs)(n.li,{children:["Ilapat ang ",(0,t.jsx)(n.strong,{children:"quantum ensemble"})," kapag lumalaki ang model width o feature complexity\u2014ang QAOA-based search ay mas graceful na nag-scale sa mga regimen na iyon."]}),"\n",(0,t.jsxs)(n.li,{children:["Gamitin ang ",(0,t.jsx)(n.strong,{children:"adaptive \u03b1-regularization"})," upang mapanatili ang sparsity at generalization nang hindi dinaragdagan ang circuit width."]}),"\n",(0,t.jsx)(n.li,{children:"Subaybayan ang QPU time at depth upang balansehin ang quality gain laban sa near-term hardware constraint."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Sama-sama, ang mga eksperimentong ito ay nagpapakita na ang quantum-optimized ensemble ay kumukumplemento sa mga klasikal na pamamaraan: muling ginagawa nila ang baseline accuracy sa maliliit na sukat habang nag-aalok ng landas sa epektibong scaling sa mas malalaki, kombinatoryal na learning problem. Habang bumubuti ang hardware, ang mga scaling advantage na ito ay inaasahang mag-compound, na nagpapalawig ng feasible na laki at lalim ng ensemble-based model lampas sa klasikal na praktikal."}),"\n",(0,t.jsx)(n.h3,{id:"evaluate-metrics-for-each-configuration",children:"Evaluate metrics for each configuration"}),"\n",(0,t.jsxs)(n.p,{children:["Ngayon ay susuriing lahat ang mga configuration - ang klasikal na AdaBoost baseline at ang tatlong quantum ensemble - gamit ang ",(0,t.jsx)(n.code,{children:"evaluate_predictions"})," helper upang makompute ang accuracy, precision, recall, at F1 sa parehong test set. Ang paghahambing na ito ay naglilinaw kung paano ang quantum optimization ay nag-scale kumpara sa klasikal na approach: sa maliliit na width, pareho silang gumaganap ng katulad; habang lumalaki ang mga ensemble, ang quantum method ay maaaring mas epektibong tuklasin ang mas malalaking hypothesis space. Ang resultang talahanayan ay kumukuha ng mga trend na ito sa pare-pareho, quantitative na anyo."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'results = []\n\n# Classical baseline\nacc_b, prec_b, rec_b, f1_b = evaluate_predictions(baseline_pred, y_test)\nresults.append(\n    {\n        "Config": "AdaBoost (Classical)",\n        "Accuracy": acc_b,\n        "Precision": prec_b,\n        "Recall": rec_b,\n        "F1": f1_b,\n    }\n)\n\n# Quantum runs\nfor label, preds in [\n    ("QEEC L=10, reg=7", qeec_pred_job_1),\n    ("QEEC L=30, reg=7", qeec_pred_job_2),\n    (f"QEEC L=60, reg=auto (\u03b1={REGULARIZATION_RATIO})", qeec_pred_job_3),\n]:\n    acc, prec, rec, f1 = evaluate_predictions(preds, y_test)\n    results.append(\n        {\n            "Config": label,\n            "Accuracy": acc,\n            "Precision": prec,\n            "Recall": rec,\n            "F1": f1,\n        }\n    )\n\ndf_results = pd.DataFrame(results)\ndf_results\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"Accuracy: 0.7893333333333333\nPrecision: 1.0\nRecall: 0.7893333333333333\nF1: 0.8822652757078987\nAccuracy: 0.868\nPrecision: 1.0\nRecall: 0.868\nF1: 0.9293361884368309\nAccuracy: 0.8946666666666667\nPrecision: 1.0\nRecall: 0.8946666666666667\nF1: 0.944405348346235\nAccuracy: 0.908\nPrecision: 1.0\nRecall: 0.908\nF1: 0.9517819706498952\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"Config  Accuracy  Precision    Recall        F1\n0          AdaBoost (Classical)  0.789333        1.0  0.789333  0.882265\n1              QEEC L=10, reg=7  0.868000        1.0  0.868000  0.929336\n2              QEEC L=30, reg=7  0.894667        1.0  0.894667  0.944405\n3  QEEC L=60, reg=auto (\u03b1=0.82)  0.908000        1.0  0.908000  0.951782\n"})}),"\n",(0,t.jsx)(n.h3,{id:"visualize-quality-trends-across-configurations",children:"Visualize quality trends across configurations"}),"\n",(0,t.jsxs)(n.p,{children:["Ang grouped bar chart sa ibaba ay naghahambing ng ",(0,t.jsx)(n.strong,{children:"Accuracy"})," at ",(0,t.jsx)(n.strong,{children:"F1"})," sa klasikal na baseline at mga quantum ensemble (",(0,t.jsx)(n.code,{children:"L=10"}),", ",(0,t.jsx)(n.code,{children:"L=30"}),", at ",(0,t.jsx)(n.code,{children:"L=60 auto-\u03b1"}),"). Ipinapakita nito kung paano nag-stabilize ang accuracy habang unti-unting bumubuti ang F1 habang tumataas ang quantum ensemble width, na nagpapakita na ang hybrid method ay nagpapanatili ng performance scaling nang walang eksponensiyal na cost growth na tipikal sa klasikal na subset selection."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'x = np.arange(len(df_results))\nwidth = 0.35\nplt.figure(figsize=(7.6, 4.6))\nplt.bar(x - width / 2, df_results["Accuracy"], width=width, label="Accuracy")\nplt.bar(x + width / 2, df_results["F1"], width=width, label="F1")\nplt.xticks(x, df_results["Config"], rotation=10)\nplt.ylabel("Score")\nplt.title("Classical vs Quantum ensemble performance")\nplt.legend()\nplt.ylim(0, 1.0)\nplt.tight_layout()\nplt.show()\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Output of the previous code cell",src:i(17991).A+"",width:"742",height:"449"})}),"\n",(0,t.jsx)(n.h3,{id:"interpretation",children:"Interpretation"}),"\n",(0,t.jsx)(n.p,{children:"Ang plot ay nagkukumpirma ng inaasahang scaling pattern. Ang klasikal na AdaBoost ay mahusay sa mas maliliit na ensemble ngunit nagiging lalong mahal na i-scale habang lumalaki ang bilang ng mga mahinang learner, dahil ang subset-selection problem nito ay lumalaki nang kombinatoryal. Ang mga quantum-enhanced model ay muling ginagawa ang klasikal na accuracy sa mababang width at nagsisimulang lampasan ito habang tumataas ang laki ng ensemble, lalo na sa ilalim ng adaptive \u03b1-regularization. Sumasalamin ito sa kakayahan ng quantum optimizer na mag-sample at magsuri ng maraming kandidatong subset nang parallel sa pamamagitan ng superposition, na nagpapanatili ng tractable search kahit sa mas mataas na width. Bagaman ang kasalukuyang hardware overhead ay nag-offset ng ilan sa teoretikal na pakinabang, ang trend ay nag-illustrate ng scaling efficiency advantage ng quantum formulation. Sa praktikal na mga termino, ang klasikal na pamamaraan ay nananatiling mas kanais-nais para sa magaan na benchmark, habang ang quantum-enhanced ensemble ay nagiging kapaki-pakinabang habang lumalaki ang model dimensionality at laki ng ensemble, na nag-aalok ng mas magandang trade-off sa pagitan ng accuracy, generalization, at computational growth."}),"\n",(0,t.jsx)(n.h2,{id:"appendix-scaling-benefits-and-enhancements",children:"Appendix: Scaling benefits and enhancements"}),"\n",(0,t.jsxs)(n.p,{children:["Ang scalability advantage ng ",(0,t.jsx)(n.code,{children:"QuantumEnhancedEnsembleClassifier"})," ay nagmumula sa kung paano ang ensemble-selection process ay nag-map sa quantum optimization.\nAng mga klasikal na ensemble learning method, tulad ng AdaBoost o random forest, ay nagiging mahal sa computational habang tumataas ang bilang ng mga mahinang learner dahil ang pagpili ng optimal subset ay isang kombinatoryal na problema na nag-scale nang eksponensiyal."]}),"\n",(0,t.jsx)(n.p,{children:"Sa kabaligtaran, ang quantum formulation \u2014 na ipinatupad dito sa pamamagitan ng Quantum Approximate Optimization Algorithm (QAOA) \u2014 ay maaaring mas epektibong tuklasin ang mga eksponensiyal na malaking search space sa pamamagitan ng pagsusuri ng maraming configuration sa superposition.\nBilang resulta, ang training time ay hindi lubhang lumalaki sa bilang ng mga learner, na nagpapahintulot sa modelo na manatiling epektibo kahit habang tumataas ang ensemble width."}),"\n",(0,t.jsx)(n.p,{children:"Bagaman ang kasalukuyang hardware ay nagpapakilala ng ilang ingay at limitasyon sa lalim, ang workflow na ito ay nagpapakita ng near-term hybrid approach kung saan nakikipagtulungan ang klasikal at quantum component: ang quantum optimizer ay nagbibigay ng mas magandang initialization landscape para sa klasikal na loop, na nagpapabuti ng convergence at huling kalidad ng modelo.\nHabang umuunlad ang mga quantum processor, ang mga scalability benefit na ito ay inaasahang lalawak sa mas malalaking dataset, mas malawak na ensemble, at mas malalim na circuit depth."}),"\n",(0,t.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"/guides/functions",children:"Introduction to Qiskit Functions"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"/guides/multiverse-computing-singularity",children:"Multiverse Computing Singularity Machine Learning"})}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"tutorial-survey",children:"Tutorial survey"}),"\n",(0,t.jsx)(n.p,{children:"Mangyaring maglaan po ng isang minuto upang magbigay ng feedback sa tutorial na ito. Ang inyong mga insight ay makakatulong sa amin na mapabuti ang aming mga alok na nilalaman at karanasan ng user."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://your.feedback.ibm.com/jfe/form/SV_3BLFkNVEuh0QBWm",children:"Link to survey"})})]})}function c(a={}){const{wrapper:n}={...(0,s.R)(),...a.components};return n?(0,t.jsx)(n,{...a,children:(0,t.jsx)(u,{...a})}):u(a)}},17991(a,n,i){i.d(n,{A:()=>e});const e="data:image/avif;base64,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"},28453(a,n,i){i.d(n,{R:()=>l,x:()=>r});var e=i(96540);const t={},s=e.createContext(t);function l(a){const n=e.useContext(s);return e.useMemo(function(){return"function"==typeof a?a(n):{...n,...a}},[n,a])}function r(a){let n;return n=a.disableParentContext?"function"==typeof a.components?a.components(t):a.components||t:l(a.components),e.createElement(s.Provider,{value:n},a.children)}}}]);